{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MODEL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s63Tf6ZbKU_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "import keras\n",
        "\n",
        "from keras.layers import Flatten,BatchNormalization\n",
        "\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.merge import add\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import Input, merge, ZeroPadding2D\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.pooling import AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "import six\n",
        "from keras.regularizers import l2\n",
        "from keras.models import Model\n",
        "\n",
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('tf')\n",
        "\n",
        "try:\n",
        "    from keras import initializations\n",
        "except ImportError:\n",
        "    from keras import initializers as initializations\n",
        "import keras.backend as K\n",
        "\n",
        "\"\"\"\n",
        "author:tslgithub\n",
        "email:mymailwith163@163.com\n",
        "time:2018-12-12\n",
        "msg: You can choose the following model to train your image, and just switch in config.py:\n",
        "    VGG16,VGG19,InceptionV3,Xception,MobileNet,AlexNet,LeNet,ZF_Net,ResNet18,ResNet34,ResNet50,ResNet101,ResNet152,DenseNet\n",
        "\"\"\"\n",
        "\n",
        "class MODEL(object):\n",
        "\n",
        "    def __init__(self,config):\n",
        "        self.config = config\n",
        "\n",
        "    def input_shape_define(self):\n",
        "        return  (self.config.normal_size, self.config.normal_size, self.config.channles)\n",
        "\n",
        "    def covn_block(self,model,kenal_number,kenal_size,padding,activation):\n",
        "        model.add(Convolution2D(kenal_number,kenal_size,padding=padding,activation=activation))\n",
        "        return model\n",
        "\n",
        "    def max_pooling_type(self,model,kenal_size,strides):\n",
        "        model.add(MaxPooling2D(pool_size=kenal_size,strides=strides))\n",
        "        return model\n",
        "\n",
        "    def mnist_net(self):\n",
        "        model = Sequential()\n",
        "        input_shape = (self.config.normal_size, self.config.normal_size, self.config.channles)\n",
        "        model.add(Convolution2D(96,(3,3),input_shape=input_shape,padding='same',activation='relu',kernel_initializer='uniform'))\n",
        "        model.add(Convolution2D(128,(3,3),padding='same',activation='relu'))\n",
        "        model.add(Convolution2D(128,(1,1),padding='same',activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        model.add(Convolution2D(256,(3,3),padding='same',activation='relu'))\n",
        "        model.add(Convolution2D(256,(1,1),padding='same',activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Convolution2D(512, (3, 3), padding='same', activation='relu'))\n",
        "        model.add(Convolution2D(512, (3, 3), padding='same', activation='relu'))\n",
        "        model.add(Convolution2D(256, (1, 1), padding='same', activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "        model.add(Convolution2D(512, (3, 3), padding='same', activation='relu'))\n",
        "        model.add(Convolution2D(512, (3, 3), padding='same', activation='relu'))\n",
        "        model.add(Convolution2D(256, (1, 1), padding='same', activation='relu'))\n",
        "        # model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        # model.add(Dense(4096,activation='relu'))\n",
        "        model.add(Dense(1024,activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        # model.add(Dense(2048, activation='relu'))\n",
        "        model.add(Dense(1024, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(self.config.classNumber,activation='softmax'))\n",
        "        return model\n",
        "\n",
        "    #VGG16\n",
        "    def TSL16(self):\n",
        "        model = Sequential()\n",
        "        input_shape = (self.config.normal_size, self.config.normal_size, self.config.channles)\n",
        "        model.add(Convolution2D(64,kernel_size=(3,3),input_shape=input_shape,padding='same',activation='relu'))\n",
        "        model.add(Convolution2D(64,kernel_size=(3,3),padding='same',activation='relu'))\n",
        "        model = self.max_pooling_type(model,kenal_size=(2,2),strides=(2,2))\n",
        "        for i in range(2):\n",
        "            model = self.covn_block(model, kenal_number=128, kenal_size=(3, 3), padding='same', activation='relu')\n",
        "\n",
        "        model = self.max_pooling_type(model,kenal_size = (2,2),strides=(2,2))\n",
        "        for i in range(3):\n",
        "            model = self.covn_block(model,kenal_number=128,  kenal_size=(3,3),  padding='same',activation='relu')\n",
        "\n",
        "        model = self.max_pooling_type(model,kenal_size=(2,2),strides=(2,2))\n",
        "        for i in range(3):\n",
        "            model = self.covn_block(model,kenal_number=512,kenal_size=(3,3),padding='same',activation='relu')\n",
        "\n",
        "        model = self.max_pooling_type(model,kenal_size=(2,2),strides=(2,2))\n",
        "        for i in range(3):\n",
        "            model = self.covn_block(model,kenal_number=512,kenal_size=(3,3),padding='same',activation='relu')\n",
        "\n",
        "        model.add(Flatten())\n",
        "        # model.add(Dense(4096,activation='relu'))\n",
        "        model.add(Dense(1024,activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(1024,activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(self.config.classNumber,activation='softmax'))\n",
        "        return model\n",
        "\n",
        "    #LeNet\n",
        "    def LeNet(self):\n",
        "        # initialize the model\n",
        "        model = Sequential()\n",
        "        inputShape = (self.config.normal_size, self.config.normal_size, self.config.channles)\n",
        "        model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=inputShape))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        # second set of CONV => RELU => POOL layers\n",
        "        model.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        # first (and only) set of FC => RELU layers\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(500))\n",
        "        model.add(Activation(\"relu\"))\n",
        "\n",
        "        # softmax classifier\n",
        "        model.add(Dense(self.config.classNumber))\n",
        "        model.add(Activation(\"softmax\"))\n",
        "        # model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "        # return the constructed network architecture\n",
        "        return model\n",
        "\n",
        "    # AlexNet\n",
        "    def AlexNet(self):\n",
        "        model = Sequential()\n",
        "        # input_shape = (64,64, self.config.channles)\n",
        "        input_shape = (self.config.normal_size, self.config.normal_size, self.config.channles)\n",
        "        model.add(Convolution2D(96, (11, 11), input_shape=input_shape,strides=(4, 4),  padding='valid',activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))#26*26\n",
        "        model.add(Convolution2D(256, (5, 5), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "        model.add(Convolution2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(Convolution2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(Convolution2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        model.add(Flatten())\n",
        "        # model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dense(1024, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        # model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dense(1024, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(self.config.classNumber, activation='softmax'))\n",
        "        # model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "        return model\n",
        "\n",
        "    def VGG16(self):\n",
        "        model = Sequential()\n",
        "        input_shape= (self.config.normal_size, self.config.normal_size, self.config.channles)\n",
        "        model.add(Convolution2D(64,(3,3),input_shape=input_shape,activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(64,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Convolution2D(256,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(256,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(256,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1024,activation='relu'))\n",
        "        model.add(Dense(1024,activation='relu'))\n",
        "        model.add(Dense(self.config.classNumber,activation='softmax'))\n",
        "        return model\n",
        "\n",
        "    def VGG19(self):\n",
        "        model = Sequential()\n",
        "        input_shape= (self.config.normal_size, self.config.normal_size, self.config.channles)\n",
        "        model.add(Convolution2D(64,(3,3),input_shape=input_shape,activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(64,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Convolution2D(256,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(256,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(256,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(256,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(Convolution2D(512,(3,3),activation='relu',padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1024,activation='relu'))\n",
        "        model.add(Dense(1024,activation='relu'))\n",
        "        model.add(Dense(self.config.classNumber,activation='softmax'))\n",
        "        return model\n",
        "\n",
        "    #ZF_Net,8 layers\n",
        "    def ZF_Net(self):\n",
        "        model = Sequential()\n",
        "        model.add(\n",
        "            Conv2D(96, (7, 7), strides=(2, 2),\n",
        "                   input_shape=(self.config.normal_size, self.config.normal_size,self.config.channles),\n",
        "                   padding='valid',\n",
        "                   activation='relu',\n",
        "                   kernel_initializer='uniform'))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "        model.add(Conv2D(256, (5, 5), strides=(2, 2), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "        model.add(Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
        "        model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(self.config.classNumber, activation='softmax'))\n",
        "        # model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "        return model\n",
        "\n",
        "#RESNET\n",
        "class ResnetBuilder(object):\n",
        "    # @staticmethod\n",
        "    def build(self,config, block_fn, repetitions):\n",
        "        \"\"\"Builds a custom ResNet like architecture.\n",
        "        Args:\n",
        "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
        "            num_outputs: The number of outputs at final softmax layer\n",
        "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
        "                The original paper used basic_block for layers < 50\n",
        "            repetitions: Number of repetitions of various block units.\n",
        "                At each block unit, the number of filters are doubled and the input size is halved\n",
        "        Returns:\n",
        "            The keras `Model`.\n",
        "        \"\"\"\n",
        "\n",
        "        input_shape = (config.normal_size,config.normal_size,config.channles)\n",
        "        num_outputs = config.classNumber\n",
        "        self._handle_dim_ordering()\n",
        "        block_fn = self._get_block(block_fn)\n",
        "\n",
        "        input = Input(shape=input_shape)\n",
        "        conv1 = self._conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
        "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
        "\n",
        "        block = pool1\n",
        "        filters = 64\n",
        "        for i, r in enumerate(repetitions):\n",
        "            block = self._residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
        "            filters *= 2\n",
        "\n",
        "        # Last activation\n",
        "        block = self._bn_relu(block)\n",
        "\n",
        "        # Classifier block\n",
        "        block_shape = K.int_shape(block)\n",
        "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
        "                                 strides=(1, 1))(block)\n",
        "\n",
        "        flatten1 = Flatten()(pool2)\n",
        "        dense = Dense(units=num_outputs,\n",
        "                      activation=\"softmax\")(flatten1)\n",
        "\n",
        "        model = Model(inputs=input, outputs=dense)\n",
        "        # model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "        return model\n",
        "\n",
        "    # @staticmethod\n",
        "    def build_resnet18(self,params):\n",
        "        return self.build(params, self.basic_block, [2, 2, 2, 2])\n",
        "\n",
        "    # @staticmethod\n",
        "    def build_resnet34(self,params):\n",
        "        return self.build(params, self.basic_block, [3, 4, 6, 3])\n",
        "\n",
        "    # @staticmethod\n",
        "    def build_resnet50(self,params):\n",
        "        return self.build(params, self.bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "    # @staticmethod\n",
        "    def build_resnet101(self,params):\n",
        "        return self.build(params, self.bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "    # @staticmethod\n",
        "    def build_resnet152(self,params):\n",
        "        return self.build(params, self.bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "    def _bn_relu(self,input):\n",
        "        \"\"\"Helper to build a BN -> relu block\n",
        "        \"\"\"\n",
        "        norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
        "        return Activation(\"relu\")(norm)\n",
        "\n",
        "    def _conv_bn_relu(self,**conv_params):\n",
        "        \"\"\"Helper to build a conv -> BN -> relu block\n",
        "        \"\"\"\n",
        "        filters = conv_params[\"filters\"]\n",
        "        kernel_size = conv_params[\"kernel_size\"]\n",
        "        strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "        kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "        padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "        kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "        def f(input):\n",
        "            conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                          strides=strides, padding=padding,\n",
        "                          kernel_initializer=kernel_initializer,\n",
        "                          kernel_regularizer=kernel_regularizer)(input)\n",
        "            return self._bn_relu(conv)\n",
        "\n",
        "        return f\n",
        "\n",
        "\n",
        "    def _bn_relu_conv(self,**conv_params):\n",
        "        \"\"\"Helper to build a BN -> relu -> conv block.\n",
        "        This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "        \"\"\"\n",
        "        filters = conv_params[\"filters\"]\n",
        "        kernel_size = conv_params[\"kernel_size\"]\n",
        "        strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "        kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "        padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "        kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "        def f(input):\n",
        "            activation = self._bn_relu(input)\n",
        "            return Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                          strides=strides, padding=padding,\n",
        "                          kernel_initializer=kernel_initializer,\n",
        "                          kernel_regularizer=kernel_regularizer)(activation)\n",
        "\n",
        "        return f\n",
        "\n",
        "\n",
        "    def _shortcut(self,input, residual):\n",
        "        \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
        "        \"\"\"\n",
        "        # Expand channles of shortcut to match residual.\n",
        "        # Stride appropriately to match residual (width, height)\n",
        "        # Should be int if network architecture is correctly configured.\n",
        "        input_shape = K.int_shape(input)\n",
        "        residual_shape = K.int_shape(residual)\n",
        "        stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
        "        stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
        "        equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
        "\n",
        "        shortcut = input\n",
        "        # 1 X 1 conv if shape is different. Else identity.\n",
        "        if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
        "            shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
        "                              kernel_size=(1, 1),\n",
        "                              strides=(stride_width, stride_height),\n",
        "                              padding=\"valid\",\n",
        "                              kernel_initializer=\"he_normal\",\n",
        "                              kernel_regularizer=l2(0.0001))(input)\n",
        "\n",
        "        return add([shortcut, residual])\n",
        "\n",
        "\n",
        "    def _residual_block(self,block_function, filters, repetitions, is_first_layer=False):\n",
        "        \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
        "        \"\"\"\n",
        "        def f(input):\n",
        "            for i in range(repetitions):\n",
        "                init_strides = (1, 1)\n",
        "                if i == 0 and not is_first_layer:\n",
        "                    init_strides = (2, 2)\n",
        "                input = block_function(filters=filters, init_strides=init_strides,\n",
        "                                       is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
        "            return input\n",
        "\n",
        "        return f\n",
        "\n",
        "\n",
        "    def basic_block(self,filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "        \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
        "        Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "        \"\"\"\n",
        "        def f(input):\n",
        "\n",
        "            if is_first_block_of_first_layer:\n",
        "                # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "                conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
        "                               strides=init_strides,\n",
        "                               padding=\"same\",\n",
        "                               kernel_initializer=\"he_normal\",\n",
        "                               kernel_regularizer=l2(1e-4))(input)\n",
        "            else:\n",
        "                conv1 = self._bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
        "                                      strides=init_strides)(input)\n",
        "\n",
        "            residual = self._bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
        "            return self._shortcut(input, residual)\n",
        "\n",
        "        return f\n",
        "\n",
        "\n",
        "    def bottleneck(self,filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "        \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
        "        Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "        Returns:\n",
        "            A final conv layer of filters * 4\n",
        "        \"\"\"\n",
        "        def f(input):\n",
        "\n",
        "            if is_first_block_of_first_layer:\n",
        "                # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "                conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
        "                                  strides=init_strides,\n",
        "                                  padding=\"same\",\n",
        "                                  kernel_initializer=\"he_normal\",\n",
        "                                  kernel_regularizer=l2(1e-4))(input)\n",
        "            else:\n",
        "                conv_1_1 = self._bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
        "                                         strides=init_strides)(input)\n",
        "\n",
        "            conv_3_3 = self._bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
        "            residual = self._bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
        "            return self._shortcut(input, residual)\n",
        "\n",
        "        return f\n",
        "\n",
        "    def _handle_dim_ordering(self):\n",
        "        global ROW_AXIS\n",
        "        global COL_AXIS\n",
        "        global CHANNEL_AXIS\n",
        "        if K.image_dim_ordering() == 'tf':\n",
        "            ROW_AXIS = 1\n",
        "            COL_AXIS = 2\n",
        "            CHANNEL_AXIS = 3\n",
        "        else:\n",
        "            CHANNEL_AXIS = 1\n",
        "            ROW_AXIS = 2\n",
        "            COL_AXIS = 3\n",
        "\n",
        "    def _get_block(self,identifier):\n",
        "        if isinstance(identifier, six.string_types):\n",
        "            res = globals().get(identifier)\n",
        "            if not res:\n",
        "                raise ValueError('Invalid {}'.format(identifier))\n",
        "            return res\n",
        "        return identifier"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}