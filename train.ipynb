{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eabMLYQcK0S2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "author:tslgithub\n",
        "email:mymailwith163@163.com\n",
        "time:2018-12-12\n",
        "msg: You can choose the following model to train your image, and just switch in config.py:\n",
        "    VGG16,VGG19,InceptionV3,Xception,MobileNet,AlexNet,LeNet,ZF_Net,esNet18,ResNet34,ResNet50,ResNet_101,ResNet_152\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "from config import config\n",
        "import numpy as np\n",
        "import os,glob,itertools,tqdm,cv2,keras\n",
        "from random import shuffle\n",
        "\n",
        "from keras.preprocessing.image import img_to_array,ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "import tensorflow as tf\n",
        "config1 = tf.ConfigProto()\n",
        "config1.gpu_options.allow_growth = True\n",
        "tf.Session(config=config1)\n",
        "\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.setrecursionlimit(10000)\n",
        "\n",
        "from Build_model import Build_model\n",
        "\n",
        "class Train(Build_model):\n",
        "    def __init__(self,config):\n",
        "        Build_model.__init__(self,config)\n",
        "\n",
        "    def get_file(self,path):\n",
        "        ends = os.listdir(path)[0].split('.')[-1]\n",
        "        img_list = glob.glob(os.path.join(path , '*.'+ends))\n",
        "        return img_list\n",
        "\n",
        "    def load_data(self):\n",
        "\n",
        "        categories = list(map(self.get_file, list(map(lambda x: os.path.join(self.train_data_path, x), os.listdir(self.train_data_path)))))\n",
        "        data_list = list(itertools.chain.from_iterable(categories))\n",
        "        shuffle(data_list)\n",
        "        images_data ,labels_idx,labels= [],[],[]\n",
        "\n",
        "        with_platform = os.name\n",
        "\n",
        "        for file in tqdm.tqdm(data_list):\n",
        "            if self.channles == 3:\n",
        "                img = cv2.imread(file)\n",
        "                # img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "                # img = cv2.threshold(img,128,255,cv2.THRESH_BINARY)[-1]\n",
        "                _, w, h = img.shape[::-1]\n",
        "            elif self.channles == 1:\n",
        "                # img=cv2.threshold(cv2.imread(file,0), 128, 255, cv2.THRESH_BINARY)[-1]\n",
        "                img = cv2.imread(file,0)\n",
        "                # img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)[-1]\n",
        "                w, h = img.shape[::-1]\n",
        "\n",
        "            if self.cut:\n",
        "                img = img[slice(int(h*self.rat),int(h-h*self.rat)),slice( int(w*self.rat),int(w-w*self.rat) )]\n",
        "            img = cv2.resize(img,(self.normal_size,self.normal_size))\n",
        "            if with_platform == 'posix':\n",
        "                label = file.split('/')[-2]\n",
        "            elif with_platform=='nt':\n",
        "                label = file.split('\\\\')[-2]\n",
        "\n",
        "            # print('img:',file,' has label:',label)\n",
        "            img = img_to_array(img)\n",
        "            images_data.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "        with open('train_class_idx.txt','r') as f:\n",
        "            lines = f.readlines()\n",
        "            lines = [line.rstrip() for line in lines]\n",
        "            for label in labels:\n",
        "                idx = lines.index(label.rstrip())\n",
        "                labels_idx.append(idx)\n",
        "\n",
        "        # images_data = np.array(images_data,dtype='float')/255.0\n",
        "        images_data = np.array(images_data, dtype='float32') / 255.0\n",
        "        labels = to_categorical(np.array(labels_idx),num_classes=self.classNumber)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(images_data,labels)\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    def mkdir(self,path):\n",
        "        if not os.path.exists(path):\n",
        "            return os.mkdir(path)\n",
        "        return path\n",
        "\n",
        "    def train(self,X_train, X_test, y_train, y_test,model):\n",
        "        print(\"*\"*50)\n",
        "        print(\"-\"*20+\"train\",config.model_name+\"-\"*20)\n",
        "        print(\"*\"*50)\n",
        "\n",
        "        tensorboard=TensorBoard(log_dir=self.mkdir(os.path.join(self.checkpoints,self.model_name) ))\n",
        "\n",
        "        lr_reduce = keras.callbacks.ReduceLROnPlateau(monitor=config.monitor,\n",
        "                                                      factor=0.1,\n",
        "                                                      patience=config.lr_reduce_patience,\n",
        "                                                      verbose=1,\n",
        "                                                      mode='auto',\n",
        "                                                      cooldown=0)\n",
        "        early_stop = keras.callbacks.EarlyStopping(monitor=config.monitor,\n",
        "                                                   min_delta=0,\n",
        "                                                   patience=config.early_stop_patience,\n",
        "                                                   verbose=1,\n",
        "                                                   mode='auto')\n",
        "        checkpoint = keras.callbacks.ModelCheckpoint(os.path.join(self.mkdir( os.path.join(self.checkpoints,self.model_name) ),self.model_name+'.h5'),\n",
        "                                                     monitor=config.monitor,\n",
        "                                                     verbose=1,\n",
        "                                                     save_best_only=True,\n",
        "                                                     save_weights_only=True,\n",
        "                                                     mode='auto',\n",
        "                                                     period=1)\n",
        "\n",
        "        if self.data_augmentation:\n",
        "            print(\"using data augmentation method\")\n",
        "            data_aug = ImageDataGenerator(\n",
        "                rotation_range=5,  # 图像旋转的角度\n",
        "                width_shift_range=0.2,  # 左右平移参数\n",
        "                height_shift_range=0.2,  # 上下平移参数\n",
        "                zoom_range=0.3,  # 随机放大或者缩小\n",
        "                horizontal_flip=True,  # 随机翻转\n",
        "            )\n",
        "\n",
        "            data_aug.fit(X_train)\n",
        "            model.fit_generator(\n",
        "                data_aug.flow(X_train, y_train, batch_size=config.batch_size),\n",
        "                steps_per_epoch=X_train.shape[0] // self.batch_size,\n",
        "                validation_data=(X_test, y_test),\n",
        "                shuffle=True,\n",
        "                epochs=self.epochs, verbose=1, max_queue_size=1000,\n",
        "                callbacks=[early_stop,checkpoint,lr_reduce,tensorboard],\n",
        "            )\n",
        "        else:\n",
        "            model.fit(x=X_train,y=y_train,\n",
        "                      batch_size=self.batch_size,\n",
        "                      validation_data=(X_test,y_test),\n",
        "                      epochs=self.epochs,\n",
        "                      callbacks=[early_stop,checkpoint,lr_reduce,tensorboard],\n",
        "                      shuffle=True,\n",
        "                      verbose=1)\n",
        "\n",
        "    def start_train(self):\n",
        "        X_train, X_test, y_train, y_test=self.load_data()\n",
        "        model = Build_model(config).build_model()\n",
        "        self.train(X_train, X_test, y_train, y_test,model)\n",
        "\n",
        "    def remove_logdir(self):\n",
        "        self.mkdir(self.checkpoints)\n",
        "        self.mkdir(os.path.join(self.checkpoints,self.model_name))\n",
        "        events = os.listdir(os.path.join(self.checkpoints,self.model_name))\n",
        "        for evs in events:\n",
        "            if \"events\" in evs:\n",
        "                os.remove(os.path.join(os.path.join(self.checkpoints,self.model_name),evs))\n",
        "\n",
        "    def mkdir(self,path):\n",
        "        if os.path.exists(path):\n",
        "            return path\n",
        "        os.mkdir(path)\n",
        "        return path\n",
        "\n",
        "\n",
        "def main():\n",
        "    train = Train(config)\n",
        "    train.remove_logdir()\n",
        "    train.start_train()\n",
        "    print('Done')\n",
        "\n",
        "if __name__=='__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}